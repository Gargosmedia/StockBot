{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "\n",
    "from datetime import datetime, date\n",
    "import yfinance as yf\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>49.82</td>\n",
       "      <td>50.26</td>\n",
       "      <td>48.97</td>\n",
       "      <td>50.26</td>\n",
       "      <td>53778000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>50.38</td>\n",
       "      <td>50.80</td>\n",
       "      <td>50.02</td>\n",
       "      <td>50.49</td>\n",
       "      <td>34079700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>49.82</td>\n",
       "      <td>49.89</td>\n",
       "      <td>49.19</td>\n",
       "      <td>49.57</td>\n",
       "      <td>39518900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>48.33</td>\n",
       "      <td>49.06</td>\n",
       "      <td>47.76</td>\n",
       "      <td>47.85</td>\n",
       "      <td>56564900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>48.03</td>\n",
       "      <td>48.86</td>\n",
       "      <td>47.83</td>\n",
       "      <td>47.99</td>\n",
       "      <td>48754000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-23</th>\n",
       "      <td>124.67</td>\n",
       "      <td>124.75</td>\n",
       "      <td>123.22</td>\n",
       "      <td>124.65</td>\n",
       "      <td>23603800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-24</th>\n",
       "      <td>125.37</td>\n",
       "      <td>125.87</td>\n",
       "      <td>124.44</td>\n",
       "      <td>124.71</td>\n",
       "      <td>14123400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-28</th>\n",
       "      <td>125.44</td>\n",
       "      <td>126.44</td>\n",
       "      <td>124.52</td>\n",
       "      <td>124.63</td>\n",
       "      <td>23128400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-29</th>\n",
       "      <td>123.86</td>\n",
       "      <td>123.87</td>\n",
       "      <td>122.53</td>\n",
       "      <td>123.42</td>\n",
       "      <td>22763100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-30</th>\n",
       "      <td>123.74</td>\n",
       "      <td>124.23</td>\n",
       "      <td>123.26</td>\n",
       "      <td>124.20</td>\n",
       "      <td>16829600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>857 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close    Volume  Dividends  Stock Splits\n",
       "Date                                                                         \n",
       "2016-01-04   49.82   50.26   48.97   50.26  53778000        0.0             0\n",
       "2016-01-05   50.38   50.80   50.02   50.49  34079700        0.0             0\n",
       "2016-01-06   49.82   49.89   49.19   49.57  39518900        0.0             0\n",
       "2016-01-07   48.33   49.06   47.76   47.85  56564900        0.0             0\n",
       "2016-01-08   48.03   48.86   47.83   47.99  48754000        0.0             0\n",
       "...            ...     ...     ...     ...       ...        ...           ...\n",
       "2019-05-23  124.67  124.75  123.22  124.65  23603800        0.0             0\n",
       "2019-05-24  125.37  125.87  124.44  124.71  14123400        0.0             0\n",
       "2019-05-28  125.44  126.44  124.52  124.63  23128400        0.0             0\n",
       "2019-05-29  123.86  123.87  122.53  123.42  22763100        0.0             0\n",
       "2019-05-30  123.74  124.23  123.26  124.20  16829600        0.0             0\n",
       "\n",
       "[857 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''getting stock history obj'''\n",
    "tickerSymbol = 'MSFT'\n",
    "tickerData = yf.Ticker(tickerSymbol)\n",
    "tickerDf = tickerData.history( start='2016-1-2', end='2019-5-31')\n",
    "tickerDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### '''getting data from dataframe'''\n",
    "dateIndexFrame=tickerDf.index\n",
    "\n",
    "'''turning all values to list'''\n",
    "valuesList = tickerDf.values.tolist()  \n",
    "\n",
    "'''getting only prices (first 4 elements) / volumes (5th) for normaliztion'''\n",
    "pricesList = [row[0:4] for row in valuesList]\n",
    "volumeList = [[row[4]] for row in valuesList]\n",
    "\n",
    "'''making scalers, they're separate to later unscale'''\n",
    "priceScaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "volumeScaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "\n",
    "'''normalizing'''\n",
    "priceListNormalized = priceScaler.fit_transform(pricesList)\n",
    "volumeListNormalized = volumeScaler.fit_transform(volumeList)\n",
    "\n",
    "'''recollecting prices/volume in one list '''\n",
    "valuesListNormalized = []\n",
    "\n",
    "'''valuesListNormalized - dataframe normalized'''\n",
    "for idx, pricesRow in enumerate(priceListNormalized):\n",
    "    valuesRow = pricesRow.tolist()\n",
    "    valuesRow.append(volumeListNormalized[idx].tolist()[0])\n",
    "    valuesListNormalized+=[valuesRow]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''ohlcvValue: Index 0-Open, 1-High, 2-Low, 3-Close, 4-Volume'''\n",
    "def getDataTarget(ohlcvValue):\n",
    "    '''predicting based on numDaysForPrediction, predicting average for next numDaysPredicting'''\n",
    "    numDaysForPrediction = 20\n",
    "    numDaysPredicting = 5\n",
    "    '''targetWeek can be used for simulating sell later on'''\n",
    "    targetWeek = []\n",
    "    \n",
    "    forPredictionFullLocal = []\n",
    "    targetFullLocal = []\n",
    "        \n",
    "    for idx in range(len(valuesListNormalized)-(numDaysForPrediction)-(numDaysPredicting)):\n",
    "        #print(idx)\n",
    "        '''making a list of numDaysForPrediction(20) from valuesListNormalized [1,2,3,..., 20] [2,3,4,...,21] ...'''\n",
    "        forPredictionSingle = valuesListNormalized[idx:idx+numDaysForPrediction]\n",
    "        forPredictionFullLocal += [forPredictionSingle]\n",
    "\n",
    "        '''make a list of targets, average of next numDaysPredicting, for 0-20, getting 20-25'''\n",
    "        targetRow = valuesListNormalized[idx+numDaysForPrediction:idx+numDaysForPrediction+numDaysPredicting]\n",
    "        targetTotal = 0\n",
    "        '''saving target week for later'''\n",
    "        targetWeek+=[targetRow]\n",
    "        \n",
    "        for day in targetRow:\n",
    "            targetTotal += day[ohlcvValue] # Index 0-Open, 1-High, 2-Low, 3-Close, 4-Volume\n",
    "        targetFullLocal +=  [targetTotal/numDaysPredicting]\n",
    "\n",
    "    return forPredictionFullLocal, targetFullLocal, targetWeek\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(832, 20, 5)\n",
      "(832,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 128)         68608     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 118,081\n",
      "Trainable params: 118,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "'''to numpy array and splitting to train and test datasets, x_train - y_train, x_test - y_test'''\n",
    "forPredictionFull, targetFull, targetWeek = getDataTarget(1);\n",
    "\n",
    "data = np.array(forPredictionFull, dtype=float)\n",
    "target = np.array(targetFull,dtype=float)\n",
    "\n",
    "randState=4\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.1, random_state=randState)\n",
    "x_nouse, test_x_targetWeek, y_nouse, test_y_targetWeek = train_test_split(targetWeek, target, test_size=0.1, random_state=randState)\n",
    "\n",
    "print (data.shape)\n",
    "print (target.shape)\n",
    "    \n",
    "'''Setup model'''\n",
    "model=Sequential()\n",
    "'''layers'''\n",
    "model.add(LSTM((128), batch_input_shape=(None, None, 5), return_sequences=True))\n",
    "model.add(LSTM((64)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "24/24 [==============================] - 2s 69ms/step - loss: 0.0743 - accuracy: 0.0000e+00 - val_loss: 0.0421 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0232 - accuracy: 0.0000e+00 - val_loss: 0.0201 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0175 - accuracy: 0.0000e+00 - val_loss: 0.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0169 - accuracy: 0.0000e+00 - val_loss: 0.0137 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0166 - accuracy: 0.0000e+00 - val_loss: 0.0192 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0159 - accuracy: 0.0000e+00 - val_loss: 0.0174 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0165 - accuracy: 0.0000e+00 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0171 - accuracy: 0.0000e+00 - val_loss: 0.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0180 - accuracy: 0.0000e+00 - val_loss: 0.0140 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0199 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0165 - accuracy: 0.0000e+00 - val_loss: 0.0209 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0184 - accuracy: 0.0000e+00 - val_loss: 0.0129 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0181 - accuracy: 0.0000e+00 - val_loss: 0.0188 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0172 - accuracy: 0.0000e+00 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0153 - accuracy: 0.0000e+00 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0162 - accuracy: 0.0000e+00 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0192 - accuracy: 0.0000e+00 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0171 - accuracy: 0.0000e+00 - val_loss: 0.0143 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0146 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0147 - accuracy: 0.0000e+00 - val_loss: 0.0169 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0149 - accuracy: 0.0000e+00 - val_loss: 0.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0153 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0164 - accuracy: 0.0000e+00 - val_loss: 0.0203 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0170 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0145 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0138 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0173 - accuracy: 0.0000e+00 - val_loss: 0.0219 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0141 - accuracy: 0.0000e+00 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0138 - accuracy: 0.0000e+00 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0160 - accuracy: 0.0000e+00 - val_loss: 0.0184 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0129 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0146 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0188 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0151 - accuracy: 0.0000e+00 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0129 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0137 - accuracy: 0.0000e+00 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0140 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0144 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0138 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0128 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0126 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0160 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.0139 - accuracy: 0.0000e+00 - val_loss: 0.0193 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0149 - accuracy: 0.0000e+00 - val_loss: 0.0195 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0126 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0212 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "24/24 [==============================] - 1s 41ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0142 - accuracy: 0.0000e+00 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0126 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0126 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0128 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0159 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0141 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0123 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0142 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0174 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0132 - accuracy: 0.0000e+00 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0166 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0141 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0148 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0138 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0144 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0143 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0125 - accuracy: 0.0000e+00 - val_loss: 0.0148 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0140 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0124 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0107 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0142 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0141 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0121 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0142 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0104 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0105 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0118 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0116 - accuracy: 0.0000e+00 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0103 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0141 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0129 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0110 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "24/24 [==============================] - 1s 32ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "24/24 [==============================] - 1s 34ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "24/24 [==============================] - 1s 33ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "24/24 [==============================] - 1s 36ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/500\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "24/24 [==============================] - 1s 39ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "24/24 [==============================] - 1s 35ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "24/24 [==============================] - 2s 101ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "24/24 [==============================] - 1s 38ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "'''training'''\n",
    "history = model.fit(x_train, y_train, epochs=500, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''testing / predicitng'''\n",
    "predictionNormalized = model.predict(x_test)\n",
    "\n",
    "'''reshaping to 5 items in row, filling with 0s '''\n",
    "predictionReshaped = [[row.tolist()[0],0,0,0] for row in predictionNormalized]\n",
    "targetReshaped = [[row.tolist(),0,0,0] for row in y_test]\n",
    "\n",
    "'''inversing trasnform for prediciton'''\n",
    "predictionInversed = priceScaler.inverse_transform(predictionReshaped)\n",
    "predictionInversed = [[firstElement[0]] for firstElement in predictionInversed]\n",
    "\n",
    "'''inversing trasnform for target'''\n",
    "targetInversed = priceScaler.inverse_transform(targetReshaped)\n",
    "targetInversed = [[firstElement[0]] for firstElement in targetInversed]\n",
    "\n",
    "'''prediciton / target scatter'''\n",
    "plt.scatter(range(len(predictionInversed)), predictionInversed , c='r')\n",
    "plt.scatter(range(len(targetInversed)), targetInversed, c='g')\n",
    "plt.show()\n",
    "\n",
    "'''loss graph'''\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Last Week Close:  89.51    \tAvg Prediction:  89.99     \tAvg Actual:  88.73 \tTrade Total:  -0.78 $\t -0.87 %\n",
      "Day 1 Price:  88.8\n",
      "Day 2 Price:  87.55\n",
      "Day 3 Price:  90.98\n",
      "Prediction reached. Selling at:  89.99\n",
      "Real Trade Total:  0.48 $\t 0.54 %\n",
      "\n",
      "\n",
      "Last Week Close:  92.25    \tAvg Prediction:  95.33     \tAvg Actual:  98.84 \tTrade Total:  6.59 $\t 7.14 %\n",
      "Day 1 Price:  98.68\n",
      "Prediction reached. Selling at:  95.33\n",
      "Real Trade Total:  3.08 $\t 3.34 %\n",
      "\n",
      "\n",
      "Last Week Close:  100.73    \tAvg Prediction:  101.27     \tAvg Actual:  103.35 \tTrade Total:  2.62 $\t 2.6 %\n",
      "Day 1 Price:  103.69\n",
      "Prediction reached. Selling at:  101.27\n",
      "Real Trade Total:  0.54 $\t 0.54 %\n",
      "\n",
      "\n",
      "Last Week Close:  61.55    \tAvg Prediction:  61.81     \tAvg Actual:  61.1 \tTrade Total:  -0.45 $\t -0.73 %\n",
      "Day 1 Price:  62.09\n",
      "Prediction reached. Selling at:  61.81\n",
      "Real Trade Total:  0.26 $\t 0.42 %\n",
      "\n",
      "\n",
      "Last Week Close:  111.9    \tAvg Prediction:  112.96     \tAvg Actual:  111.46 \tTrade Total:  -0.44 $\t -0.39 %\n",
      "Day 1 Price:  112.31\n",
      "Day 2 Price:  112.28\n",
      "Day 3 Price:  112.13\n",
      "Day 4 Price:  111.8\n",
      "Day 5 Price:  112.88\n",
      "Prediction not reached. Selling at:  112.80999999999999\n",
      "Real Trade Total:  0.91 $\t 0.81 %\n",
      "\n",
      "\n",
      "Last Week Close:  95.27    \tAvg Prediction:  95.67     \tAvg Actual:  97.22 \tTrade Total:  1.95 $\t 2.05 %\n",
      "Day 1 Price:  96.48\n",
      "Prediction reached. Selling at:  95.67\n",
      "Real Trade Total:  0.4 $\t 0.42 %\n",
      "\n",
      "\n",
      "Last Week Close:  61.66    \tAvg Prediction:  61.95     \tAvg Actual:  62.98 \tTrade Total:  1.32 $\t 2.14 %\n",
      "Day 1 Price:  62.33\n",
      "Prediction reached. Selling at:  61.95\n",
      "Real Trade Total:  0.29 $\t 0.47 %\n",
      "\n",
      "\n",
      "Last Week Close:  101.48    \tAvg Prediction:  102.14     \tAvg Actual:  105.59 \tTrade Total:  4.11 $\t 4.05 %\n",
      "Day 1 Price:  105.18\n",
      "Prediction reached. Selling at:  102.14\n",
      "Real Trade Total:  0.66 $\t 0.65 %\n",
      "\n",
      "\n",
      "Last Week Close:  46.55    \tAvg Prediction:  46.77     \tAvg Actual:  46.7 \tTrade Total:  0.15 $\t 0.32 %\n",
      "Day 1 Price:  46.73\n",
      "Day 2 Price:  47.2\n",
      "Prediction reached. Selling at:  46.77\n",
      "Real Trade Total:  0.22 $\t 0.47 %\n",
      "\n",
      "\n",
      "Last Week Close:  59.21    \tAvg Prediction:  59.27     \tAvg Actual:  58.67 \tTrade Total:  -0.54 $\t -0.91 %\n",
      "Day 1 Price:  59.44\n",
      "Prediction reached. Selling at:  59.27\n",
      "Real Trade Total:  0.06 $\t 0.1 %\n",
      "\n",
      "\n",
      "Last Week Close:  79.75    \tAvg Prediction:  79.95     \tAvg Actual:  81.03 \tTrade Total:  1.28 $\t 1.61 %\n",
      "Day 1 Price:  79.76\n",
      "Day 2 Price:  81.48\n",
      "Prediction reached. Selling at:  79.95\n",
      "Real Trade Total:  0.2 $\t 0.25 %\n",
      "\n",
      "\n",
      "Last Week Close:  89.9    \tAvg Prediction:  90.19     \tAvg Actual:  89.01 \tTrade Total:  -0.89 $\t -0.99 %\n",
      "Day 1 Price:  90.76\n",
      "Prediction reached. Selling at:  90.19\n",
      "Real Trade Total:  0.29 $\t 0.32 %\n",
      "\n",
      "\n",
      "Last Week Close:  79.47    \tAvg Prediction:  80.09     \tAvg Actual:  81.62 \tTrade Total:  2.15 $\t 2.71 %\n",
      "Day 1 Price:  81.48\n",
      "Prediction reached. Selling at:  80.09\n",
      "Real Trade Total:  0.62 $\t 0.78 %\n",
      "\n",
      "\n",
      "Last Week Close:  88.55    \tAvg Prediction:  88.96     \tAvg Actual:  90.9 \tTrade Total:  2.35 $\t 2.65 %\n",
      "Day 1 Price:  89.75\n",
      "Prediction reached. Selling at:  88.96\n",
      "Real Trade Total:  0.41 $\t 0.46 %\n",
      "\n",
      "\n",
      "Last Week Close:  59.91    \tAvg Prediction:  60.07     \tAvg Actual:  59.18 \tTrade Total:  -0.73 $\t -1.22 %\n",
      "Day 1 Price:  59.75\n",
      "Day 2 Price:  60.02\n",
      "Day 3 Price:  59.98\n",
      "Day 4 Price:  60.1\n",
      "Prediction reached. Selling at:  60.07\n",
      "Real Trade Total:  0.16 $\t 0.27 %\n",
      "\n",
      "\n",
      "Last Week Close:  56.49    \tAvg Prediction:  56.85     \tAvg Actual:  57.74 \tTrade Total:  1.25 $\t 2.21 %\n",
      "Day 1 Price:  57.84\n",
      "Prediction reached. Selling at:  56.85\n",
      "Real Trade Total:  0.36 $\t 0.64 %\n",
      "\n",
      "\n",
      "Last Week Close:  101.01    \tAvg Prediction:  102.08     \tAvg Actual:  106.47 \tTrade Total:  5.46 $\t 5.41 %\n",
      "Day 1 Price:  104.5\n",
      "Prediction reached. Selling at:  102.08\n",
      "Real Trade Total:  1.07 $\t 1.06 %\n",
      "\n",
      "\n",
      "Last Week Close:  46.98    \tAvg Prediction:  47.03     \tAvg Actual:  46.7 \tTrade Total:  -0.28 $\t -0.6 %\n",
      "Day 1 Price:  47.57\n",
      "Prediction reached. Selling at:  47.03\n",
      "Real Trade Total:  0.05 $\t 0.11 %\n",
      "\n",
      "\n",
      "Last Week Close:  103.59    \tAvg Prediction:  108.35     \tAvg Actual:  107.08 \tTrade Total:  3.49 $\t 3.37 %\n",
      "Day 1 Price:  106.29\n",
      "Day 2 Price:  108.55\n",
      "Prediction reached. Selling at:  108.35\n",
      "Real Trade Total:  4.76 $\t 4.6 %\n",
      "\n",
      "\n",
      "Last Week Close:  95.64    \tAvg Prediction:  95.7     \tAvg Actual:  96.23 \tTrade Total:  0.59 $\t 0.62 %\n",
      "Day 1 Price:  97.28\n",
      "Prediction reached. Selling at:  95.7\n",
      "Real Trade Total:  0.06 $\t 0.06 %\n",
      "\n",
      "\n",
      "Last Week Close:  71.26    \tAvg Prediction:  71.39     \tAvg Actual:  71.14 \tTrade Total:  -0.12 $\t -0.17 %\n",
      "Day 1 Price:  71.35\n",
      "Day 2 Price:  71.83\n",
      "Prediction reached. Selling at:  71.39\n",
      "Real Trade Total:  0.13 $\t 0.18 %\n",
      "\n",
      "\n",
      "Last Week Close:  47.09    \tAvg Prediction:  48.51     \tAvg Actual:  47.41 \tTrade Total:  0.32 $\t 0.68 %\n",
      "Day 1 Price:  47.14\n",
      "Day 2 Price:  48.1\n",
      "Day 3 Price:  48.83\n",
      "Prediction reached. Selling at:  48.51\n",
      "Real Trade Total:  1.42 $\t 3.02 %\n",
      "\n",
      "\n",
      "Last Week Close:  70.6    \tAvg Prediction:  70.72     \tAvg Actual:  69.27 \tTrade Total:  -1.33 $\t -1.88 %\n",
      "Day 1 Price:  70.81\n",
      "Prediction reached. Selling at:  70.72\n",
      "Real Trade Total:  0.12 $\t 0.17 %\n",
      "\n",
      "\n",
      "Last Week Close:  46.64    \tAvg Prediction:  46.81     \tAvg Actual:  46.06 \tTrade Total:  -0.58 $\t -1.24 %\n",
      "Day 1 Price:  46.6\n",
      "Day 2 Price:  46.62\n",
      "Day 3 Price:  46.95\n",
      "Prediction reached. Selling at:  46.81\n",
      "Real Trade Total:  0.17 $\t 0.36 %\n",
      "\n",
      "\n",
      "Last Week Close:  52.66    \tAvg Prediction:  52.71     \tAvg Actual:  53.09 \tTrade Total:  0.43 $\t 0.82 %\n",
      "Day 1 Price:  53.68\n",
      "Prediction reached. Selling at:  52.71\n",
      "Real Trade Total:  0.05 $\t 0.09 %\n",
      "\n",
      "\n",
      "Last Week Close:  54.95    \tAvg Prediction:  55.07     \tAvg Actual:  55.63 \tTrade Total:  0.68 $\t 1.24 %\n",
      "Day 1 Price:  56.65\n",
      "Prediction reached. Selling at:  55.07\n",
      "Real Trade Total:  0.12 $\t 0.22 %\n",
      "\n",
      "\n",
      "Last Week Close:  65.72    \tAvg Prediction:  65.76     \tAvg Actual:  65.53 \tTrade Total:  -0.19 $\t -0.29 %\n",
      "Day 1 Price:  66.36\n",
      "Prediction reached. Selling at:  65.76\n",
      "Real Trade Total:  0.04 $\t 0.06 %\n",
      "\n",
      "\n",
      "Last Week Close:  49.85    \tAvg Prediction:  50.1     \tAvg Actual:  49.94 \tTrade Total:  0.09 $\t 0.18 %\n",
      "Day 1 Price:  50.19\n",
      "Prediction reached. Selling at:  50.1\n",
      "Real Trade Total:  0.25 $\t 0.5 %\n",
      "\n",
      "\n",
      "Last Week Close:  106.9    \tAvg Prediction:  106.96     \tAvg Actual:  104.5 \tTrade Total:  -2.4 $\t -2.25 %\n",
      "Day 1 Price:  108.65\n",
      "Prediction reached. Selling at:  106.96\n",
      "Real Trade Total:  0.06 $\t 0.06 %\n",
      "\n",
      "Trades Made:  29\n",
      "\n",
      "Passive Balance Total: \t 13.14 $\n",
      "AI Balance Total: \t 26.1 $  \tAvg Trade Perc Change:  0.97 %\n",
      "Real AI Balance Total: \t 17.24 $  \tAvg Trade Perc Change:  0.72 %\n",
      "\n",
      "tooHighNum:  37 \n",
      "tooLowNum:  46 \n",
      "goodGuessNum:  1\n"
     ]
    }
   ],
   "source": [
    "def tradeSimulation():\n",
    "    '''getting close list to simulate buying on close the day before prediction week'''\n",
    "    x_testPrices = [row[-1][0:4] for row in x_test] #get last day before prediciton week, and strip volume from list\n",
    "    x_testInversed = priceScaler.inverse_transform(x_testPrices) #inverse normalization\n",
    "    x_testOnlyClose = [round(row[3],2) for row in x_testInversed] #get Close price of the day\n",
    "\n",
    "    tooHighNum = 0\n",
    "    tooLowNum = 0\n",
    "    goodGuessNum = 0\n",
    "    balanceTotal = 0\n",
    "    balancePercTotal = 0\n",
    "    \n",
    "    realBalanceTotal = 0\n",
    "    realBalancePercTotal = 0\n",
    "    \n",
    "    numTrades=0\n",
    "    passiveTotal = 0\n",
    "    \n",
    "    for idx in range(len(x_testOnlyClose)):\n",
    "\n",
    "        lastWeekClose = x_testOnlyClose[idx]\n",
    "        weekPredictionAvg = round(predictionInversed[idx][0],2)\n",
    "        weekActualAvg = round(targetInversed[idx][0],2)\n",
    "\n",
    "        if weekPredictionAvg < weekActualAvg: tooLowNum+=1\n",
    "        elif weekPredictionAvg > weekActualAvg: tooHighNum+=1\n",
    "        else: goodGuessNum+=1\n",
    "    \n",
    "        '''calculating balance without ai interference'''   \n",
    "        tradeTotal = round(weekActualAvg - lastWeekClose,2)\n",
    "        passiveTotal+=tradeTotal\n",
    "        \n",
    "        '''only buying those bot liked'''\n",
    "        if lastWeekClose < weekPredictionAvg: #if next week looks good, we buy a stock and sell on predicted price (tradeTotal)\n",
    "            '''selling on next week average price (we don't know it)'''\n",
    "            numTrades+=1\n",
    "\n",
    "            tradePercTotal = round((tradeTotal/lastWeekClose*100),2)\n",
    "            balanceTotal+=tradeTotal\n",
    "            balancePercTotal+=tradePercTotal\n",
    "\n",
    "            print(\"\\n\\nLast Week Close: \", lastWeekClose, \"   \\tAvg Prediction: \", weekPredictionAvg, \"    \\tAvg Actual: \", weekActualAvg, \"\\tTrade Total: \", tradeTotal,\"$\\t\", tradePercTotal,\"%\")\n",
    "\n",
    "            \n",
    "            '''selling on predicted price if reached, if not selling on week close'''\n",
    "            \n",
    "            targetWeekPrices = [day[0:4]for day in test_x_targetWeek[idx]]\n",
    "            targetWeekPricesInversed = priceScaler.inverse_transform(targetWeekPrices)\n",
    "            \n",
    "            gotPredicted=False;\n",
    "\n",
    "            for num, day in enumerate(targetWeekPricesInversed):  \n",
    "                maxDayPrice = day[1]\n",
    "                print(\"Day\", num+1,\"Price: \",round(maxDayPrice,2))\n",
    "                if maxDayPrice > weekPredictionAvg:\n",
    "                    print(\"Prediction reached. Selling at: \", weekPredictionAvg)\n",
    "                    realTradeTotal = round(weekPredictionAvg - lastWeekClose,2)\n",
    "                    gotPredicted=True\n",
    "                    break;\n",
    "            if not gotPredicted:\n",
    "                closeWeekPrice = targetWeekPricesInversed[-1][3]\n",
    "                print(\"Prediction not reached. Selling at: \", closeWeekPrice)\n",
    "                realTradeTotal = round(closeWeekPrice - lastWeekClose,2)\n",
    "         \n",
    "            realTradePercTotal = round((realTradeTotal/lastWeekClose*100),2)\n",
    "            realBalanceTotal+=realTradeTotal\n",
    "            realBalancePercTotal+=realTradePercTotal\n",
    "\n",
    "            print(\"Real Trade Total: \", realTradeTotal,\"$\\t\", realTradePercTotal,\"%\")\n",
    "\n",
    "\n",
    "    if (numTrades==0):\n",
    "        numTrades=-1\n",
    "\n",
    "    print(\"\\nTrades Made: \", numTrades)\n",
    "    print(\"\\nPassive Balance Total: \\t\", round(passiveTotal,2),\"$\")\n",
    "    print(\"AI Balance Total: \\t\", round(balanceTotal,2), \"$  \\tAvg Trade Perc Change: \",round(balancePercTotal/numTrades,2),\"%\" )\n",
    "    print(\"Real AI Balance Total: \\t\", round(realBalanceTotal,2), \"$  \\tAvg Trade Perc Change: \",round(realBalancePercTotal/numTrades,2),\"%\" )\n",
    "\n",
    "    print(\"\\ntooHighNum: \", tooHighNum, \"\\ntooLowNum: \",tooLowNum,\"\\ngoodGuessNum: \",goodGuessNum)\n",
    "\n",
    "tradeSimulation()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
